{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HH analysis\n",
    "\n",
    "This notebook provides the necessary tools to produce the $HH\\rightarrow b\\bar{b} g g$ and $HH\\rightarrow b\\bar{b} b\\bar{b}$ analysis. Firstly, let's import some useful python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import treeloop.looper as l\n",
    "import treeloop.configvar as cv\n",
    "import treeloop.configsel as cs\n",
    "import numpy as np\n",
    "import awkward as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jets_name='GenJet'\n",
    "# jets_name='AKTjet'\n",
    "jets_vars = ['.PT', '.Eta', '.Phi', '.Mass', '.BTag', '_size']\n",
    "\n",
    "particles_name='Particle'\n",
    "particles_vars = ['.PT', '.Eta', '.Phi', '.Mass', '.PID', '_size']\n",
    "\n",
    "loopers = {\n",
    "    'sig': {\n",
    "        'kl0.bbbb': l.looper('Delphes',\n",
    "                             ['../../grid_outputs/delphes/user.valentem.delphes.HH_kl0.10TeV.bbbb.220905_0117.root'],\n",
    "                             branches=[f'{jets_name}{v}' for v in jets_vars] + [f'{particles_name}{v}' for v in particles_vars],\n",
    "                            ),\n",
    "        # 'kl1.bbbb': l.looper('Delphes',\n",
    "        #                      ['../../grid_outputs/delphes/user.valentem.delphes.HH_kl1.10TeV.bbbb.220905_0117.root'],\n",
    "        #                      branches=[f'{jets_name}{v}' for v in jets_vars] + [f'{particles_name}{v}' for v in particles_vars],\n",
    "        #                     ),\n",
    "        # 'kl5.bbbb': l.looper('Delphes',\n",
    "        #                      ['../../grid_outputs/delphes/user.valentem.delphes.HH_kl5.10TeV.bbbb.220905_0118.root'],\n",
    "        #                      branches=[f'{jets_name}{v}' for v in jets_vars] + [f'{particles_name}{v}' for v in particles_vars],\n",
    "        #                     ),\n",
    "    },\n",
    "    'bkg': {\n",
    "        'bbbb': l.looper('Delphes',\n",
    "                             ['../../grid_outputs/delphes/user.valentem.delphes.mumu_bbbb.10TeV.NONE.220905_0118.root'],\n",
    "                             branches=[f'{jets_name}{v}' for v in jets_vars] + [f'{particles_name}{v}' for v in particles_vars],\n",
    "                            ),\n",
    "        # 'bbcc': l.looper('Delphes',\n",
    "        #                      ['../../grid_outputs/delphes/user.valentem.delphes.mumu_bbcc.10TeV.NONE.220905_1853.root'],\n",
    "        #                      branches=[f'{jets_name}{v}' for v in jets_vars] + [f'{particles_name}{v}' for v in particles_vars],\n",
    "        #                     ),\n",
    "        # 'bbuu': l.looper('Delphes',\n",
    "        #                      ['../../grid_outputs/delphes/user.valentem.delphes.mumu_bbuu.10TeV.NONE.220905_1854.root'],\n",
    "        #                      branches=[f'{jets_name}{v}' for v in jets_vars] + [f'{particles_name}{v}' for v in particles_vars],\n",
    "        #                     ),\n",
    "    },\n",
    "}\n",
    "\n",
    "##############\n",
    "# Variables\n",
    "##############\n",
    "\n",
    "###### Jets\n",
    "\n",
    "jet_n    = lambda event,sel_name=None: cv.var(event,f'{jets_name}_size',sel_name=sel_name)\n",
    "jet_pt   = lambda event,sel_name=None: cv.var(event,f'{jets_name}.PT',sel_name=sel_name)\n",
    "jet_eta  = lambda event,sel_name=None: cv.var(event,f'{jets_name}.Eta',sel_name=sel_name)\n",
    "jet_phi  = lambda event,sel_name=None: cv.var(event,f'{jets_name}.Phi',sel_name=sel_name)\n",
    "jet_mass = lambda event,sel_name=None: cv.var(event,f'{jets_name}.Mass',sel_name=sel_name)\n",
    "jet_btag = lambda event,sel_name=None: cv.var(event,f'{jets_name}.BTag',sel_name=sel_name)\n",
    "jet_i    = lambda event,sel_name=None: ak.argsort(ak.argsort(jet_pt(event,sel_name=sel_name), ascending=False))\n",
    "\n",
    "def jets_b_match(event, to_match, sel_name=None):\n",
    "    b_jets=jet_btag(event, sel_name=sel_name)\n",
    "    ret=None\n",
    "    for t in to_match:\n",
    "        _pass = (b_jets == t)\n",
    "        if ret is None: ret = _pass\n",
    "        else: ret = ret+ _pass\n",
    "    return ret\n",
    "\n",
    "jets_b_loo = lambda event, sel_name=None: jets_b_match(event, [4,5,6,7], sel_name=sel_name)\n",
    "jets_b_med = lambda event, sel_name=None: jets_b_match(event, [2,3,6,7], sel_name=sel_name)\n",
    "jets_b_tig = lambda event, sel_name=None: jets_b_match(event, [1,3,5,7], sel_name=sel_name)\n",
    "\n",
    "ntag_loo = lambda event, sel_name=None: ak.count_nonzero(jets_b_loo(event,sel_name=sel_name),axis=1)\n",
    "ntag_med = lambda event, sel_name=None: ak.count_nonzero(jets_b_med(event,sel_name=sel_name),axis=1)\n",
    "ntag_tig = lambda event, sel_name=None: ak.count_nonzero(jets_b_tig(event,sel_name=sel_name),axis=1)\n",
    "\n",
    "###### Particles\n",
    "\n",
    "particles_n    = lambda event,sel_name=None: cv.var(event,f'{particles_name}_size',sel_name=sel_name)\n",
    "particles_pt   = lambda event,sel_name=None: cv.var(event,f'{particles_name}.PT',sel_name=sel_name)\n",
    "\n",
    "##############\n",
    "# Selections\n",
    "##############\n",
    "\n",
    "sel_ntag_med_two = lambda event,**kwargs: ntag_med(event)==2\n",
    "sel_ntag_med_two.__name__ = \"sel_ntag_loo_two\"\n",
    "\n",
    "sel_ntag_med_four = lambda event,**kwargs: ntag_med(event)>=4\n",
    "sel_ntag_med_four.__name__ = \"sel_ntag_loo_four\"\n",
    "\n",
    "sel_two_jet = lambda event, **kwargs: jet_n(event) >= 2\n",
    "sel_two_jet.__name__ = \"sel_two_jet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jet_vectors(event, sel_name=None):\n",
    "    pt   = jet_pt(event, sel_name=sel_name)\n",
    "    eta  = jet_eta(event, sel_name=sel_name)\n",
    "    phi  = jet_phi(event, sel_name=sel_name)\n",
    "    mass = jet_mass(event, sel_name=sel_name)\n",
    "\n",
    "    import vector as v\n",
    "    return v.zip({'pt':pt,'eta':eta,'phi':phi,'mass':mass})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['../../grid_outputs/delphes/user.valentem.delphes.HH_kl0.10TeV.bbbb.220905_0117.root']\n",
      "1 ['../../grid_outputs/delphes/user.valentem.delphes.HH_kl0.10TeV.bbbb.220905_0117.root']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-af30575250e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     sample_type : {\n\u001b[1;32m     23\u001b[0m         \u001b[0msample_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_sel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloopers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         } for sample_type in loopers.keys()\n\u001b[0m\u001b[1;32m     25\u001b[0m     }\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-af30575250e2>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m     sample_type : {\n\u001b[1;32m     23\u001b[0m         \u001b[0msample_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_sel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloopers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         } for sample_type in loopers.keys()\n\u001b[0m\u001b[1;32m     25\u001b[0m     }\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-af30575250e2>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     21\u001b[0m vals = {\n\u001b[1;32m     22\u001b[0m     sample_type : {\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0msample_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain_sel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloopers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         } for sample_type in loopers.keys()\n\u001b[1;32m     25\u001b[0m     }\n",
      "\u001b[0;32m~/MuonCollider/whizard-pythia-delphes/notebooks/treeloop/looper.py\u001b[0m in \u001b[0;36mvariables\u001b[0;34m(self, var_dict, selection, weight, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_updateVariables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvar_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MuonCollider/whizard-pythia-delphes/notebooks/treeloop/looper.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, updateFunction, variable, selection, weight, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Looping on file {0} named \\'{1}\\''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddVariablesToEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddSelectionToEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "main_sel=cs.baseline\n",
    "# main_sel =sel_ntag_med_four\n",
    "\n",
    "vars_dict = {\n",
    "    #Useful variables\n",
    "    'jets_b_loo' : jets_b_loo,\n",
    "    'jets_b_med' : jets_b_med,\n",
    "    'jets_b_tig' : jets_b_tig,\n",
    "    'ntag_loo'   : ntag_loo,\n",
    "    'ntag_med'   : ntag_med,\n",
    "    'ntag_tig'   : ntag_tig,\n",
    "    'jet_pt'     : jet_pt,\n",
    "    'jet_eta'    : jet_eta,\n",
    "    'jet_phi'    : jet_phi,\n",
    "    'jet_mass'   : jet_mass,\n",
    "    'jet_i'      : jet_i,\n",
    "    'jets_4vect' : jet_vectors,\n",
    "    'particles_n' : particles_n,\n",
    "}\n",
    "\n",
    "vals = {\n",
    "    sample_type : {\n",
    "        sample_name: loop.variables(vars_dict,selection=main_sel) for sample_name,loop in loopers[sample_type].items()\n",
    "        } for sample_type in loopers.keys()\n",
    "    }\n",
    "    \n",
    "# leadjet_descr = {'fir': 0, 'sec': 1, 'thi': 2, 'fou': 3}\n",
    "\n",
    "# sels = {\n",
    "#     sample_type : {\n",
    "#         sample: {\n",
    "#                 f'sel_{jname}_jet': (vals[sample_type][sample]['jet_i'][0] == index) \n",
    "#                 for jname,index in leadjet_descr.items()\n",
    "#             } for sample in vals[sample_type].keys()\n",
    "#     } for sample_type in vals.keys()\n",
    "# }\n",
    "\n",
    "# for sample_type in vals.keys():\n",
    "#     for sample in vals[sample_type].keys():\n",
    "#         for _v in ['pt','eta','phi','mass']:\n",
    "#             for jname in leadjet_descr.keys():\n",
    "#                 vals[sample_type][sample][f'{jname}jet_{_v}'] = [ak.flatten(vals[sample_type][sample][f'jet_{_v}'][i][sels[sample_type][sample][f'sel_{jname}_jet']],axis=1) for i in [0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vals['sig']['kl1.bbbb']['ntag_med'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getAdaptiveBinning(*argv,bins=None,range=None,ncounts=5,**kwargs):\n",
    "    assert bins is not None, 'Please specify bins argument for getAdaptiveBinning(...)'\n",
    "    assert range is not None, 'Please specify range argument for getAdaptiveBinning(...)'\n",
    "    dx = abs(range[1]-range[0])/float(bins)\n",
    "    x_low = range[0]\n",
    "    x_high = range[0]\n",
    "    binning=[]\n",
    "\n",
    "    while x_low <= range[1]:\n",
    "        print(binning)\n",
    "        binning+=[x_low]\n",
    "        i=0\n",
    "        _next_step=True\n",
    "        while _next_step and x_high < range[1]:\n",
    "            i+=1\n",
    "            x_high = x_low + i*dx\n",
    "            for vals in argv:\n",
    "                _counts = ak.sum((vals>x_low) * (vals <= x_high) )\n",
    "                if _counts < ncounts:\n",
    "                    _next_step=False\n",
    "                    break\n",
    "        x_low=x_high\n",
    "    if binning[-1]!=range[1]:\n",
    "        binning[-1]=range[1]\n",
    "    return binning\n",
    "\n",
    "def makeHistComp(vals_sig,vals_bkg,doAdaptiveBinning=False,*args,**kwargs):\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    # bins = getAdaptiveBinning(vals_sig, vals_bkg, **kwargs)\n",
    "    # print(bins)\n",
    "    h_sig = plt.hist(vals_sig, *args, histtype='step', label='Signal', **kwargs)\n",
    "    h_bkg = plt.hist(vals_bkg, *args, histtype='step', label='Background', **kwargs)\n",
    "    # plt.xlabel('ntag')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return h_sig, h_bkg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = 'ntag_tig'\n",
    "h_sig,h_bkg = makeHistComp(vals['bkg']['bbcc'][varname][0], vals['bkg']['bbbb'][varname][0],\n",
    "                           bins=10, \n",
    "                           density=False, \n",
    "                           range=(0, 10), \n",
    "                           doAdaptiveBinning=True,\n",
    "                           log=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname = 'firjet_pt'\n",
    "h_sig, h_bkg = makeHistComp(vals['sig']['kl1.bbbb'][varname][0], vals['bkg']['bbcc'][varname][0],\n",
    "                            bins=100,\n",
    "                            density=False,\n",
    "                            range=(0, 10000),\n",
    "                            log=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_sig[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testSignificance(bkg,sgn,systs=None, ntoys=2000):\n",
    "\n",
    "    import pyhf\n",
    "    pyhf.set_backend(pyhf.tensorlib, 'minuit')\n",
    "    import scipy.stats as st\n",
    "\n",
    "    data = [s+b for s,b in zip(sgn,bkg)]\n",
    "\n",
    "\n",
    "    model = pyhf.simplemodels.uncorrelated_background(\n",
    "        signal=sgn, \n",
    "        bkg=bkg, \n",
    "        bkg_uncertainty=systs if systs is not None else [0. for x in bkg] #no systematics\n",
    "    )\n",
    "    print(f'Testing significance for sgn={sgn} and bkg={bkg}')\n",
    "\n",
    "    obs = data + model.config.auxdata\n",
    "    test_mu = 0.0\n",
    "    pval = pyhf.infer.hypotest(test_mu, obs, model, test_stat=\"q0\", calctype='toybased', ntoys=ntoys)\n",
    "    sig = st.norm.isf(pval)\n",
    "    return pval,sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSignificance([6400.],[3*80.]) #this should give 3 sigma significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSignificance(list(h_bkg[0])[:5],[x/100. for x in h_sig[0]][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "rows_to_sel = ['ntag_tig', 'ntag_med','firjet_pt','firjet_eta','secjet_pt','secjet_pt']\n",
    "\n",
    "df_X = ak.to_pandas({f'{sample}': { \n",
    "                        f'{rowname}': vals[sample][rowname][0] \n",
    "                        for rowname in rows_to_sel\n",
    "                        } \n",
    "                   for sample in ['sig','bkg']\n",
    "                   })\n",
    "_N = df_X.shape[0]\n",
    "df_y = pd.DataFrame({'sig':[1]*_N,\n",
    "                     'bkg':[0]*_N \n",
    "                    })\n",
    "\n",
    "df_w = pd.DataFrame({'sig':[0.1]*_N,\n",
    "                     'bkg':[0.7]*_N \n",
    "                   })\n",
    "\n",
    "df_X = pd.concat([df_X['sig'], df_X['bkg']])\n",
    "df_y = pd.concat([df_y['sig'], df_y['bkg']])\n",
    "df_w = pd.concat([df_w['sig'], df_w['bkg']])\n",
    "\n",
    "print(_N)\n",
    "print(df_X.shape[0])\n",
    "print(df_X.shape[0]/_N)\n",
    "\n",
    "# n_train = round(df.shape[0]/2)\n",
    "# X_train = scaler.fit_transform(df.values[:n_train])\n",
    "# X_test  = scaler.transform(df.values[n_train:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 12\n",
    "test_size = 0.20\n",
    "\n",
    "X_train, X_val, y_train, y_val, w_train, w_val = train_test_split(df_X, df_y, df_w,\n",
    "                                                  test_size=test_size, random_state=state)\n",
    "\n",
    "lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "    gb_clf = GradientBoostingClassifier(\n",
    "        n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "    gb_clf.fit(X_train, y_train, sample_weight=w_train)\n",
    "\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(\n",
    "        gb_clf.score(X_train, y_train, sample_weight=w_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(\n",
    "        gb_clf.score(X_val, y_val, sample_weight=w_val)))\n",
    "\n",
    "gb_clf2 = GradientBoostingClassifier(\n",
    "    n_estimators=20, learning_rate=0.5, max_features=2, max_depth=2, random_state=0)\n",
    "gb_clf2.fit(X_train, y_train,sample_weight=w_train)\n",
    "predictions = gb_clf2.predict(X_val)\n",
    "predictions_prob = gb_clf2.predict_proba(X_val)\n",
    "decision_func = gb_clf2.decision_function(X_val)\n",
    "scores = gb_clf2.score(X_val, y_val, sample_weight=w_val)\n",
    "# print(predictions)\n",
    "# print(scores,)\n",
    "print(decision_func)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, predictions, sample_weight=w_val))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_val, predictions, sample_weight=w_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_sig, h_bkg = makeHistComp(decision_func[y_val == 1], decision_func[y_val == 0],\n",
    "                            bins=100,\n",
    "                            density=False,\n",
    "                            range=(-10, 10),\n",
    "                            log=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 12\n",
    "test_size = 0.20\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_X, df_y,\n",
    "                                                  test_size=test_size, random_state=state)\n",
    "\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100)\n",
    "    # learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred=rf_clf.predict(X_val)\n",
    "\n",
    "print(\"Learning rate: \", learning_rate)\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(\n",
    "    rf_clf.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(\n",
    "    rf_clf.score(X_val, y_val)))\n",
    "\n",
    "print('Predictions:')\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "# gb_clf2 = GradientBoostingClassifier(\n",
    "#     n_estimators=20, learning_rate=0.5, max_features=2, max_depth=2, random_state=0)\n",
    "# gb_clf2.fit(X_train, y_train)\n",
    "# predictions = gb_clf2.predict(X_val)\n",
    "# print(np.sum(predictions))\n",
    "\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_matrix(y_val, predictions))\n",
    "\n",
    "# print(\"Classification Report\")\n",
    "# print(classification_report(y_val, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_clf = XGBClassifier()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "score = xgb_clf.score(X_val, y_val)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffc0e7004edd790e60668f7af0ed383fd7abc79e43dc18390786fae04475d979"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
